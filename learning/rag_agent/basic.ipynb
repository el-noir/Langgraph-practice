{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a79082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma database created successfully with 6 documents, each including metadata and timing references!\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize HuggingFace embeddings (local)\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Documents with longer content, metadata, and timing references\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\"Artificial intelligence (AI) has transformed modern technology over the past decade (2010-2025). \n",
    "Machine learning algorithms can process and analyze vast amounts of data in seconds, something that used to take hours in the early 2010s. \n",
    "Natural language processing allows computers to understand and generate human language with near-human accuracy in 2024. \n",
    "Computer vision enables machines to interpret visual information in real time, with applications in surveillance and autonomous vehicles since 2015. \n",
    "AI systems are increasingly sophisticated, capable of reasoning, problem-solving, and decision-making in complex environments as of 2025.\"\"\",\n",
    "        metadata={\"source\": \"ai_file.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Climate change has accelerated in the past 50 years (1970-2025), becoming one of the most urgent global challenges. \n",
    "Rising temperatures have caused polar ice caps to melt faster since the 1990s, leading to a 20 cm increase in sea levels over the past three decades. \n",
    "Extreme weather events, such as floods and hurricanes, have increased in frequency by 30% since 2000. \n",
    "Transitioning to renewable energy sources such as solar, wind, and hydroelectric power is critical by 2030 to mitigate environmental damage. \n",
    "International collaboration and policy reforms are ongoing, with major climate summits held annually since 1992.\"\"\",\n",
    "        metadata={\"source\": \"climate_file.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Maintaining a healthy lifestyle has become increasingly emphasized over the last 20 years (2005-2025). \n",
    "Regular exercise strengthens the cardiovascular system and muscles, with recommendations of at least 150 minutes per week. \n",
    "Balanced nutrition provides essential vitamins and minerals, a focus of dietary guidelines updated every five years. \n",
    "Adequate sleep, typically 7-9 hours per night, allows the body to recover physically and mentally. \n",
    "Stress management techniques, including mindfulness and meditation, have been widely adopted in workplaces since 2015, enhancing quality of life and preventing burnout.\"\"\",\n",
    "        metadata={\"source\": \"health_file.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Renewable energy technologies have advanced rapidly worldwide over the last 15 years (2010-2025). \n",
    "Solar panels convert sunlight directly into electricity, with efficiency improving by 50% since 2010. \n",
    "Wind turbines harness atmospheric currents, producing record-breaking energy outputs in 2023. \n",
    "Hydroelectric power generates electricity from flowing water, with new plants built between 2015-2022. \n",
    "Geothermal energy has been utilized increasingly since 2018, contributing to 2% of global electricity in 2024. \n",
    "Adopting these sustainable technologies by 2030 is critical to combat climate change.\"\"\",\n",
    "        metadata={\"source\": \"renewable_file.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Space exploration has progressed significantly from 1960 to 2025, revealing many cosmic mysteries. \n",
    "Telescopes launched in the 1990s and 2000s observe distant galaxies, nebulae, and other celestial phenomena. \n",
    "Rovers exploring Mars since 2004 continue to search for signs of past or present life. \n",
    "The International Space Station, operational since 2000, supports microgravity research and international collaboration. \n",
    "Private companies have been developing commercial space travel since 2010, with several manned missions planned between 2023-2025.\"\"\",\n",
    "        metadata={\"source\": \"space_file.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Digital transformation has reshaped business operations over the past decade (2010-2025). \n",
    "Cloud computing provides scalable infrastructure and has grown at an annual rate of 25% since 2015. \n",
    "Big data analytics started booming in the early 2010s, enabling insights for smarter decision-making. \n",
    "Cybersecurity measures have become critical, with incidents increasing yearly since 2012. \n",
    "Automation and AI-driven tools streamline repetitive tasks, increasing efficiency by up to 40% in large enterprises from 2020-2025.\"\"\",\n",
    "        metadata={\"source\": \"digital_file.txt\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create Chroma vector database\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "print(\"Chroma database created successfully with 6 documents, each including metadata and timing references!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832427fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc6209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'space_file.txt'}, page_content='Space exploration continues to reveal the mysteries of the universe. \\nTelescopes allow observation of distant galaxies, nebulae, and other celestial phenomena. \\nRovers and landers explore planetary surfaces, searching for signs of past or present life. \\nThe International Space Station supports microgravity research and international collaboration in space science. \\nPrivate companies are developing commercial space travel, aiming to make space more accessible for humanity in the near future.'),\n",
       " Document(metadata={'source': 'digital_file.txt'}, page_content='Digital transformation has reshaped business operations over the past decade (2010-2025). \\nCloud computing provides scalable infrastructure and has grown at an annual rate of 25% since 2015. \\nBig data analytics started booming in the early 2010s, enabling insights for smarter decision-making. \\nCybersecurity measures have become critical, with incidents increasing yearly since 2012. \\nAutomation and AI-driven tools streamline repetitive tasks, increasing efficiency by up to 40% in large enterprises from 2020-2025.'),\n",
       " Document(metadata={}, page_content='Healthy lifestyle choices contribute to overall well-being.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"When was telescope launched?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cd02b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatMessagePromptTemplate\nrole\n  Field required [type=missing, input_value={'prompt': PromptTemplate...nQuestion: {question}')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatMessagePromptTemplate\n\u001b[32m      3\u001b[39m template = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mAnswer the question based only on the following context: \u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m prompt = \u001b[43mChatMessagePromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI\\Langgraph-practice\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:259\u001b[39m, in \u001b[36mBaseStringMessagePromptTemplate.from_template\u001b[39m\u001b[34m(cls, template, template_format, partial_variables, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a class from a string template.\u001b[39;00m\n\u001b[32m    239\u001b[39m \n\u001b[32m    240\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m \u001b[33;03m    A new instance of this class.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    254\u001b[39m prompt = PromptTemplate.from_template(\n\u001b[32m    255\u001b[39m     template,\n\u001b[32m    256\u001b[39m     template_format=template_format,\n\u001b[32m    257\u001b[39m     partial_variables=partial_variables,\n\u001b[32m    258\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI\\Langgraph-practice\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI\\Langgraph-practice\\.venv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatMessagePromptTemplate\nrole\n  Field required [type=missing, input_value={'prompt': PromptTemplate...nQuestion: {question}')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatMessagePromptTemplate.from_template(template, role=\"human\")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283363f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(retriever.invoke(x)),\n",
    "        \"question\": lambda x: x\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "qa_chain.invoke(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
